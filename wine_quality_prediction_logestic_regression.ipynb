{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9715384615384616\n",
      "Confusion Matrix:\n",
      " [[  9   0  23]\n",
      " [  0 464   4]\n",
      " [  6   4 790]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.28      0.38        32\n",
      "           1       0.99      0.99      0.99       468\n",
      "           2       0.97      0.99      0.98       800\n",
      "\n",
      "    accuracy                           0.97      1300\n",
      "   macro avg       0.85      0.75      0.78      1300\n",
      "weighted avg       0.97      0.97      0.97      1300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ReDI\\anaconda3\\envs\\Pandas\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "  # Load the datasets\n",
    "red_wine_data_set = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\", sep=\";\")\n",
    "white_wine_data_set = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", sep=\";\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Adding the \"quality_label\" and \"wine_type\" Columns:\n",
    "\n",
    "   # Add the \"quality_label\" column\n",
    "red_wine_data_set['quality_label'] = red_wine_data_set['quality'].apply(lambda value: 'low' if value <= 5 else ('medium' if value <= 7 else 'high'))\n",
    "white_wine_data_set['quality_label'] = white_wine_data_set['quality'].apply(lambda value: 'low' if value <= 5 else ('medium' if value <= 7 else 'high'))\n",
    "\n",
    "   # Add the \"wine_type\" column\n",
    "red_wine_data_set['wine_type'] = 'red'\n",
    "white_wine_data_set['wine_type'] = 'white'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. Combining the Datasets:\n",
    "combined_wine = pd.concat([white_wine_data_set, red_wine_data_set], axis=0) #  axis=0 indicates that the dataframes should be concatenated vertically\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 4. Encoding Categorical Features:\n",
    "   # Since machine learning models like Logistic Regression expect numerical input, \n",
    "   # we encode the categorical features 'quality_label' and 'wine_type' using one-hot encoding.\n",
    "   # This converts them into binary columns.\n",
    "\n",
    "\n",
    " # Encode \"quality_label\" using .cat.codes\n",
    " # low: 1 / medium: 2 / high: 0\n",
    "combined_wine['quality_label_encoded'] = combined_wine['quality_label'].astype('category').cat.codes\n",
    "\n",
    " # Encode \"wine_type\" using .cat.codes\n",
    " # White: 1 / Red: 0\n",
    "combined_wine['wine_type_encoded'] = combined_wine['wine_type'].astype('category').cat.codes\n",
    "\n",
    "\n",
    " # Identify categorical columns\n",
    "categorical_columns_to_drop = ['wine_type', 'quality_label']\n",
    "\n",
    "\n",
    " # Drop categorical columns\n",
    "combined_wine = combined_wine.drop(categorical_columns_to_drop, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 5. Splitting the Data for Machine Learning:\n",
    "  # We split the data into features (X) and the target variable (y), which is 'wine_type_white' indicating whether the wine is white (1) or not (0).\n",
    "  # The dataset is divided into training (80%) and testing (20%) sets.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xq = combined_wine.drop('quality_label_encoded', axis=1)  # Features\n",
    "yq = combined_wine['quality_label_encoded']  # Target variable\n",
    "\n",
    "Xq_train, Xq_test, yq_train, yq_test = train_test_split(Xq, yq, test_size=0.2, random_state=42)\n",
    "\n",
    "'''\n",
    " # To exclude many columns when setting your training features\n",
    "  # List of columns to exclude\n",
    "columns_to_exclude = ['volatile acidity', 'citric acid', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'fixed acidity', 'residual sugar']\n",
    "\n",
    "  # Select columns for training by excluding the ones in the list\n",
    "X = combined_wine.drop(columns=columns_to_exclude)\n",
    "\n",
    "  # Your target variable\n",
    "y = combined_wine['wine_type_encoded']\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 6. Applying Logistic Regression:\n",
    "  # We import the Logistic Regression model from scikit-learn and create an instance of the model.\n",
    "  # Then, we fit the model to the training data.\n",
    "  # Fitting the model means training the model on training data using the .fit method provided in sklearn.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(Xq_train, yq_train)\n",
    "\n",
    "\n",
    "# 7. Evaluating the Model:\n",
    "  # To assess the model's performance, we use it to make predictions on the test data.\n",
    "  # We calculate accuracy, confusion matrix, and a classification report to provide more detailed metrics.\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "yq_pred = model.predict(Xq_test)\n",
    "\n",
    "accuracy = accuracy_score(yq_test, yq_pred)\n",
    "confusion = confusion_matrix(yq_test, yq_pred)\n",
    "report = classification_report(yq_test, yq_pred)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", confusion)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "\n",
    "# classification_report and confusion_matrix are two commonly used tools in machine learning \n",
    "# for evaluating the performance of classification models, \n",
    "# especially in tasks where you are predicting categorical outcomes (i.e., classes or labels). \n",
    "# They provide valuable insights into how well your model is performing and where it might be making errors. \n",
    "# These tools are typically used in supervised learning tasks, such as binary or multiclass classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ReDI\\anaconda3\\envs\\Pandas\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\ReDI\\anaconda3\\envs\\Pandas\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\ReDI\\anaconda3\\envs\\Pandas\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\ReDI\\anaconda3\\envs\\Pandas\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores for Each Fold: [0.95923077 0.94307692 0.93148576 0.90839107 0.926097  ]\n",
      "Mean Accuracy: 0.9336563036655414\n",
      "Standard Deviation of Accuracy: 0.016988159185775238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ReDI\\anaconda3\\envs\\Pandas\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# to evaluate machine learning models through cross-validation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Assuming you've loaded and preprocessed your dataset, X and y should be defined here.\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Perform 5-fold cross-validation with accuracy as the scoring metric\n",
    "scores = cross_val_score(model, Xq, yq, cv=5, scoring='accuracy')\n",
    "\n",
    "# View the results\n",
    "print(\"Accuracy Scores for Each Fold:\", scores)\n",
    "print(\"Mean Accuracy:\", np.mean(scores))\n",
    "print(\"Standard Deviation of Accuracy:\", np.std(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
